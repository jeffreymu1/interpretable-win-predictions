{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASON = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be done: make this scalable to defenses too (no easy way to verify data)\n",
    "all = pd.read_csv(f'../s{SEASON}/s{SEASON}.csv')\n",
    "atk_df = all[all['type'] == 'atk']\n",
    "\n",
    "# also\n",
    "striker_df = pd.read_csv('apply_figs/f_striker_attributes.csv')\n",
    "special_df = pd.read_csv('apply_figs/f_special_attributes.csv')\n",
    "\n",
    "# and\n",
    "affinity_map = pd.read_csv('save_figs/terrain.csv')\n",
    "color_map = pd.read_csv('save_figs/color_map.csv')\n",
    "\n",
    "# using these dfs\n",
    "atk_df\n",
    "striker_df\n",
    "special_df\n",
    "affinity_map\n",
    "color_map\n",
    "\n",
    "# properties\n",
    "list_str = ['d1','d2','d3','d4','a1','a2','a3','a4']; list_sp = ['ds1','ds2','as1','as2']\n",
    "\n",
    "def_slots = ['d1', 'd2', 'd3', 'd4', 'ds1', 'ds2']\n",
    "atk_slots = ['a1', 'a2', 'a3', 'a4', 'as1', 'as2']\n",
    "\n",
    "def_slots_strikers = ['d1', 'd2', 'd3', 'd4']\n",
    "atk_slots_strikers = ['a1', 'a2', 'a3', 'a4']\n",
    "\n",
    "# partial info\n",
    "def_slots_partial = ['d1','ds1','ds2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expands original dataset to include char-specific features, defined in respective dfs\n",
    "def expand_features_wide(df: pd.DataFrame, list_ftrs_to_expand: list[str], ftr_to_merge: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    for slot in list_ftrs_to_expand:\n",
    "        tmp = ftr_to_merge.copy()\n",
    "        tmp.columns = [f'{slot}_{c}' for c in tmp.columns]\n",
    "        out = out.merge(tmp, how='left', left_on=slot, right_on=f'{slot}_char', validate='m:1')\n",
    "        out = out.drop(columns=[f'{slot}_char'])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain_drops = {\n",
    "    \"urban\": (\"_outdoor\", \"_indoor\"),\n",
    "    \"outdoor\": (\"_urban\", \"_indoor\"),\n",
    "    \"indoor\": (\"_urban\", \"_outdoor\")}\n",
    "\n",
    "# removes extraneous terrain attributes on map affinity\n",
    "\n",
    "def remove_terrains(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    terrain = df['affinity'].iloc[0]\n",
    "    \n",
    "    to_drop = terrain_drops.get(terrain)\n",
    "    cols_dropped = [c for c in out.columns if c.endswith(to_drop)]\n",
    "    out = out.drop(columns=cols_dropped)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert terrain multipliers into features\n",
    "\n",
    "def expand_terrain_cols(df: pd.DataFrame, affinity_map: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    out = df.copy()\n",
    "    suffixes = ('dmg_mult', 'block_r')\n",
    "    terrain = atk_df[\"affinity\"].iloc[0]\n",
    "\n",
    "    aff_cols = [c for c in out.columns if c.endswith(f'_affinity_{terrain}')]\n",
    "\n",
    "    maps = {s: dict(zip(affinity_map['affinity'], affinity_map[s])) for s in suffixes}\n",
    "\n",
    "    for col in aff_cols:\n",
    "        for s in suffixes:\n",
    "            out[f'{col}_{s}'] = out[col].map(maps[s])\n",
    "\n",
    "    out = out.drop(columns=aff_cols)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some team classifiers\n",
    "\n",
    "# add up d1-d4 roles, make a new column, same for a1-a4 roles # make one for each unique role, so two extra sets of columns with role number of columns there\n",
    "# do the same for position\n",
    "# aggregate sum hp, mean hp, min hp, max hp, same for atk, same for def, then also do the subtraction\n",
    "\n",
    "# adds row-wise aggregates for a given stat\n",
    "def add_team_aggregates_cont(\n",
    "    df: pd.DataFrame, stat: str, def_slots_f: list[str], def_slots_p: list[str], atk_slots: list[str]) -> pd.DataFrame:\n",
    "    \n",
    "    out = df.copy()\n",
    "\n",
    "    def_cols_f = [f\"{s}_{stat}\" for s in def_slots_f]\n",
    "    def_cols_p = [f\"{s}_{stat}\" for s in def_slots_p]\n",
    "    atk_cols = [f\"{s}_{stat}\" for s in atk_slots]\n",
    "\n",
    "    # aggregate row-wise\n",
    "    # all units (post)\n",
    "    out[f\"def_{stat}_sum_FULL\"]  = out[def_cols_f].sum(axis=1)\n",
    "    out[f\"def_{stat}_mean_FULL\"] = out[def_cols_f].mean(axis=1)\n",
    "    out[f\"def_{stat}_std_FULL\"] = out[def_cols_f].std(axis=1)\n",
    "    # out[f\"def_{stat}_min_FULL\"]  = out[def_cols_f].min(axis=1)\n",
    "    # out[f\"def_{stat}_max_FULL\"]  = out[def_cols_f].max(axis=1)\n",
    "\n",
    "    # seen units (pre)\n",
    "    out[f\"def_{stat}_sum_PARTIAL\"]  = out[def_cols_p].sum(axis=1)\n",
    "    out[f\"def_{stat}_mean_PARTIAL\"] = out[def_cols_p].mean(axis=1)\n",
    "    out[f\"def_{stat}_std_PARTIAL\"] = out[def_cols_p].std(axis=1)\n",
    "    # out[f\"def_{stat}_min_PARTIAL\"]  = out[def_cols_p].min(axis=1)\n",
    "    # out[f\"def_{stat}_max_PARTIAL\"]  = out[def_cols_p].max(axis=1)\n",
    "\n",
    "    # always have own units\n",
    "    out[f\"atk_{stat}_sum\"]  = out[atk_cols].sum(axis=1)\n",
    "    out[f\"atk_{stat}_mean\"] = out[atk_cols].mean(axis=1)\n",
    "    out[f\"atk_{stat}_std\"] = out[atk_cols].std(axis=1)\n",
    "    # out[f\"atk_{stat}_min\"]  = out[atk_cols].min(axis=1)\n",
    "    # out[f\"atk_{stat}_max\"]  = out[atk_cols].max(axis=1)\n",
    "\n",
    "    # diffs between atk and def teams\n",
    "    out[f\"diff_{stat}_sum_PARTIAL\"] = out[f\"atk_{stat}_sum\"] - out[f\"def_{stat}_sum_PARTIAL\"]\n",
    "    out[f\"diff_{stat}_mean_PARTIAL\"] = out[f\"atk_{stat}_mean\"] - out[f\"def_{stat}_mean_PARTIAL\"]\n",
    "    out[f\"diff_{stat}_std_PARTIAL\"] = out[f\"atk_{stat}_std\"] - out[f\"def_{stat}_std_PARTIAL\"]\n",
    "\n",
    "    out[f\"diff_{stat}_sum_FULL\"] = out[f\"atk_{stat}_sum\"] - out[f\"def_{stat}_sum_FULL\"]\n",
    "    out[f\"diff_{stat}_mean_FULL\"] = out[f\"atk_{stat}_mean\"] - out[f\"def_{stat}_mean_FULL\"]\n",
    "    out[f\"diff_{stat}_std_FULL\"] = out[f\"atk_{stat}_std\"] - out[f\"def_{stat}_std_FULL\"]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds row-wise aggregates for a given categorical stat\n",
    "def add_team_aggregates_cat(\n",
    "    df: pd.DataFrame, stat: str, def_slots_f: list[str], atk_slots: list[str]) -> pd.DataFrame:\n",
    "\n",
    "    out = df.copy()\n",
    "\n",
    "    def_cols_f = [f\"{s}_{stat}\" for s in def_slots_f]\n",
    "    atk_cols = [f\"{s}_{stat}\" for s in atk_slots]\n",
    "\n",
    "    def_stacked = out[def_cols_f].stack()\n",
    "    atk_stacked = out[atk_cols].stack()\n",
    "\n",
    "    def_counts = pd.get_dummies(def_stacked).groupby(level=0).sum().reindex(out.index)\n",
    "    atk_counts = pd.get_dummies(atk_stacked).groupby(level=0).sum().reindex(out.index)\n",
    "\n",
    "    def_props = def_counts/len(def_cols_f)\n",
    "    atk_props = atk_counts/len(atk_cols)\n",
    "\n",
    "    def_props.columns = [f\"def_{stat}_{c}_prop_FULL\" for c in def_props.columns]\n",
    "    atk_props.columns = [f\"atk_{stat}_{c}_prop_FULL\" for c in atk_props.columns]\n",
    "\n",
    "    out = out.join(def_props).join(atk_props)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could be extended with detailed ex logs, first deaths, time to win, damage dealt\n",
    "\n",
    "# compute the expected multiplier of units against defs\n",
    "\n",
    "def compute_exp_mult(df: pd.DataFrame, type: str, color_map: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    atk_slots = [\"a1\", \"a2\", \"a3\", \"a4\"]\n",
    "    def_slots = [\"d1\", \"d2\", \"d3\", \"d4\"]\n",
    "\n",
    "    M = color_map.set_index(\"attack_color\").copy()\n",
    "    M_vals = M.values\n",
    "    atk_idx = {k: i for i, k in enumerate(M.index.tolist())}\n",
    "    def_idx = {k: j for j, k in enumerate(M.columns.tolist())}\n",
    "\n",
    "    def _codes(arr2d: np.ndarray, mapping: dict) -> np.ndarray:\n",
    "        v = np.vectorize(lambda x: mapping.get(x, -1), otypes=[int])\n",
    "        return v(arr2d)\n",
    "\n",
    "    def _mult(atk_colors: np.ndarray, def_colors: np.ndarray) -> np.ndarray:\n",
    "        a = _codes(atk_colors, atk_idx)\n",
    "        d = _codes(def_colors, def_idx)\n",
    "        mult = M_vals[a[:, :, None], d[:, None, :]]\n",
    "\n",
    "        return mult\n",
    "\n",
    "    def _get(cols: list[str]) -> np.ndarray:\n",
    "        return out[cols].to_numpy()\n",
    "\n",
    "    if type == \"striker\":\n",
    "        A_atk   = _get([f\"{s}_atk\" for s in atk_slots])\n",
    "        A_hp    = _get([f\"{s}_max_hp\" for s in atk_slots])\n",
    "        A_atkc  = _get([f\"{s}_atk_type\" for s in atk_slots])\n",
    "        A_defc  = _get([f\"{s}_def_type\" for s in atk_slots])\n",
    "\n",
    "        D_atk   = _get([f\"{s}_atk\" for s in def_slots])\n",
    "        D_hp    = _get([f\"{s}_max_hp\" for s in def_slots])\n",
    "        D_atkc  = _get([f\"{s}_atk_type\" for s in def_slots])\n",
    "        D_defc  = _get([f\"{s}_def_type\" for s in def_slots])\n",
    "\n",
    "        mult_A_to_D = _mult(A_atkc, D_defc)\n",
    "        mult_D_to_A = _mult(D_atkc, A_defc)\n",
    "\n",
    "        denom_A_to_D = A_atk[:, :, None] * mult_A_to_D\n",
    "        denom_D_to_A = D_atk[:, :, None] * mult_D_to_A\n",
    "\n",
    "        ttk_A_to_D = D_hp[:, None, :] / denom_A_to_D\n",
    "        ttk_D_to_A = A_hp[:, None, :] / denom_D_to_A\n",
    "\n",
    "        # store each unit ttk\n",
    "        ttk_a_to_def = np.nanmean(ttk_A_to_D, axis=2)\n",
    "        for i, s in enumerate(atk_slots):\n",
    "            out[f\"ttk_{s}_to_def\"] = ttk_a_to_def[:, i]\n",
    "\n",
    "        ttk_d_to_atk = np.nanmean(ttk_D_to_A, axis=2)\n",
    "        for i, s in enumerate(def_slots):\n",
    "            out[f\"ttk_{s}_to_atk\"] = ttk_d_to_atk[:, i]\n",
    "\n",
    "        # store avg atk\n",
    "        ttk_avg_A_to_D = np.nanmean(ttk_A_to_D, axis=(1, 2))\n",
    "        ttk_avg_D_to_A = np.nanmean(ttk_D_to_A, axis=(1, 2))\n",
    "\n",
    "        out[\"ttk_avg_atk_to_def\"] = ttk_avg_A_to_D\n",
    "        out[\"ttk_avg_def_to_atk\"] = ttk_avg_D_to_A\n",
    "        out[\"ttk_delta_strikers\"] = out[\"ttk_avg_def_to_atk\"] - out[\"ttk_avg_atk_to_def\"]\n",
    "\n",
    "    elif type == \"special\":\n",
    "        atk_sp_slots = [\"as1\", \"as2\"]\n",
    "        def_sp_slots = [\"ds1\", \"ds2\"]\n",
    "\n",
    "        # atk specials -> def strikers\n",
    "        AS_atk = _get([f\"{s}_atk\" for s in atk_sp_slots])\n",
    "        AS_atkc = _get([f\"{s}_atk_type\" for s in atk_sp_slots])\n",
    "        D_hp = _get([f\"{s}_max_hp\" for s in def_slots])\n",
    "        D_defc = _get([f\"{s}_def_type\" for s in def_slots])\n",
    "\n",
    "        mult_AS_to_D = _mult(AS_atkc, D_defc)\n",
    "        denom_AS_to_D = AS_atk[:, :, None] * mult_AS_to_D\n",
    "        denom_AS_to_D[denom_AS_to_D <= 0] = np.nan\n",
    "\n",
    "        ttk_AS_to_D = D_hp[:, None, :] / denom_AS_to_D\n",
    "\n",
    "        AS_deals = _get([f\"{s}_deals_dmg\" for s in atk_sp_slots])\n",
    "        AS_can_dmg = np.isin(AS_deals, [\"yes\"])\n",
    "        mask = np.broadcast_to((~AS_can_dmg)[:, :, None], ttk_AS_to_D.shape)\n",
    "        ttk_AS_to_D[mask] = np.nan\n",
    "\n",
    "        ttk_as_to_def_str = np.nanmean(ttk_AS_to_D, axis=2)\n",
    "        for i, s in enumerate(atk_sp_slots):\n",
    "            out[f\"ttk_{s}_to_def_str\"] = ttk_as_to_def_str[:, i]\n",
    "        out[\"ttk_avg_atkS_to_def_str\"] = np.nanmean(ttk_AS_to_D, axis=(1, 2))\n",
    "\n",
    "        # def specials -> atk strikers\n",
    "        DS_atk  = _get([f\"{s}_atk\" for s in def_sp_slots])\n",
    "        DS_atkc = _get([f\"{s}_atk_type\" for s in def_sp_slots])\n",
    "        A_hp    = _get([f\"{s}_max_hp\" for s in atk_slots])\n",
    "        A_defc  = _get([f\"{s}_def_type\" for s in atk_slots])\n",
    "\n",
    "        mult_DS_to_A = _mult(DS_atkc, A_defc)\n",
    "        denom_DS_to_A = DS_atk[:, :, None] * mult_DS_to_A\n",
    "        denom_DS_to_A[denom_DS_to_A <= 0] = np.nan\n",
    "\n",
    "        ttk_DS_to_A = A_hp[:, None, :] / denom_DS_to_A\n",
    "\n",
    "        DS_deals = _get([f\"{s}_deals_dmg\" for s in def_sp_slots])\n",
    "        DS_can_dmg = np.isin(DS_deals, [\"yes\"])\n",
    "        mask = np.broadcast_to((~DS_can_dmg)[:, :, None], ttk_DS_to_A.shape)\n",
    "        ttk_DS_to_A[mask] = np.nan\n",
    "\n",
    "        ttk_ds_to_atk_str = np.nanmean(ttk_DS_to_A, axis=2)\n",
    "        for i, s in enumerate(def_sp_slots):\n",
    "            out[f\"ttk_{s}_to_atk_str\"] = ttk_ds_to_atk_str[:, i]\n",
    "        out[\"ttk_avg_defS_to_atk_str\"] = np.nanmean(ttk_DS_to_A, axis=(1, 2))\n",
    "\n",
    "        out[\"ttk_delta_specials\"] = out[\"ttk_avg_defS_to_atk_str\"] - out[\"ttk_avg_atkS_to_def_str\"]\n",
    "\n",
    "    else:\n",
    "        raise ValueError('try type=\"striker\" or type=\"special\"')\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1c/h8d9s2m12xl44x37yf7xzw5h0000gn/T/ipykernel_74688/2402676085.py:110: RuntimeWarning: Mean of empty slice\n",
      "  ttk_ds_to_atk_str = np.nanmean(ttk_DS_to_A, axis=2)\n"
     ]
    }
   ],
   "source": [
    "# pipeline\n",
    "\n",
    "copy = atk_df.copy()\n",
    "\n",
    "c = expand_features_wide(copy, list_str, striker_df)\n",
    "\n",
    "c = expand_features_wide(c, list_sp, special_df)\n",
    "\n",
    "c = remove_terrains(c)\n",
    "\n",
    "c = expand_terrain_cols(c, affinity_map)\n",
    "\n",
    "# these can change, speculating that these are most imp\n",
    "for stat_cont in ['ex_cost', 'ex_length', 'max_hp', 'atk', 'def', 'healing', 'accuracy', 'evasion', 'crit']:\n",
    "    c = add_team_aggregates_cont(c, stat_cont, def_slots, def_slots_partial, atk_slots)\n",
    "\n",
    "# total categorical vars, also can add more, in terms of strikers-only, encode roles and positioning info (heuristic)\n",
    "for stat_cat in ['role', 'position']:\n",
    "    c = add_team_aggregates_cat(c, stat_cat, def_slots_strikers, atk_slots_strikers)\n",
    "\n",
    "c = compute_exp_mult(c, 'striker', color_map)\n",
    "c = compute_exp_mult(c, 'special', color_map)\n",
    "\n",
    "c.to_csv('../s9/s9_working_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
