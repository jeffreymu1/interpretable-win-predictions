{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.validation import check_array, check_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper class, implemented with xgboost docs\n",
    "class XGBTrainEarlyStoppingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators=10000,\n",
    "        early_stopping_rounds=50,\n",
    "        validation_fraction=0.1,\n",
    "        random_state=0,\n",
    "        n_jobs=1,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        subsample=1.0,\n",
    "        colsample_bytree=1.0,\n",
    "        reg_lambda=1.0,\n",
    "        min_child_weight=1.0,\n",
    "        gamma=0.0):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.validation_fraction = validation_fraction\n",
    "\n",
    "        self.random_state = random_state\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.subsample = subsample\n",
    "        self.colsample_bytree = colsample_bytree\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.min_child_weight = min_child_weight\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y, accept_sparse=True)\n",
    "        X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "            X, y,\n",
    "            test_size=self.validation_fraction,\n",
    "            random_state=self.random_state,\n",
    "            stratify=y)\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "        params = {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"logloss\",\n",
    "            \"seed\": self.random_state,\n",
    "            \"nthread\": self.n_jobs,\n",
    "            \"max_depth\": self.max_depth,\n",
    "            \"eta\": self.learning_rate,\n",
    "            \"subsample\": self.subsample,\n",
    "            \"colsample_bytree\": self.colsample_bytree,\n",
    "            \"lambda\": self.reg_lambda,\n",
    "            \"min_child_weight\": self.min_child_weight,\n",
    "            \"gamma\": self.gamma,\n",
    "            \"verbosity\": 0}\n",
    "\n",
    "        self.booster_ = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=self.n_estimators,\n",
    "            evals=[(dval, \"val\")],\n",
    "            early_stopping_rounds=self.early_stopping_rounds,\n",
    "            verbose_eval=False,\n",
    "        )\n",
    "\n",
    "        # best_ntree_limit\n",
    "        self.best_ntree_limit_ = getattr(self.booster_, \"best_ntree_limit\", None)\n",
    "        self.best_iteration_ = getattr(self.booster_, \"best_iteration\", None)\n",
    "        return self\n",
    "\n",
    "    def _pred_kwargs(self):\n",
    "        if self.best_ntree_limit_ is not None:\n",
    "            return {\"ntree_limit\": self.best_ntree_limit_}\n",
    "        if self.best_iteration_ is not None:\n",
    "            return {\"iteration_range\": (0, self.best_iteration_ + 1)}\n",
    "        return {}\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = check_array(X, accept_sparse=True)\n",
    "        d = xgb.DMatrix(X)\n",
    "        p = self.booster_.predict(d, **self._pred_kwargs())\n",
    "        p = np.asarray(p).ravel()\n",
    "        return np.column_stack([1.0 - p, p])\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)[:, 1]\n",
    "        return (proba >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class: 1\n"
     ]
    }
   ],
   "source": [
    "# final csv\n",
    "full_csv = pd.read_csv('../data/processed/s9_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 571)\n",
      "(514,)\n"
     ]
    }
   ],
   "source": [
    "# the target var\n",
    "y = full_csv['outcome']\n",
    "X = full_csv.drop(columns=['outcome'])\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect features\n",
    "\n",
    "# splitting by numeric and cat features. note: all features with numbers are num in this dataset\n",
    "def split_num_cat_by_value(X: pd.DataFrame):\n",
    "    coerced = X.apply(lambda s: pd.to_numeric(s, errors=\"coerce\"))\n",
    "    is_numeric_col = coerced.notna().sum(axis=0).eq(X.notna().sum(axis=0))\n",
    "\n",
    "    num_ftrs = X.columns[is_numeric_col].tolist()\n",
    "    cat_ftrs = X.columns[~is_numeric_col].tolist()\n",
    "    \n",
    "    return num_ftrs, cat_ftrs\n",
    "\n",
    "num_ftrs, cat_ftrs = split_num_cat_by_value(X)\n",
    "\n",
    "# no ordinal ftrs in this dataset\n",
    "ordinal_ftrs = []\n",
    "ordinal_cats = []\n",
    "\n",
    "# no overlapping features\n",
    "assert set(num_ftrs) & set(cat_ftrs) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ttk_ds1_to_atk_str']\n",
      "num na rows: 3\n",
      "na row indices: [85, 86, 87]\n"
     ]
    }
   ],
   "source": [
    "test = X.drop(columns=cat_ftrs)\n",
    "cols_with_missing = test.columns[test.isna().any()].tolist()\n",
    "\n",
    "print(cols_with_missing)\n",
    "\n",
    "bad_rows = test.index[test[cols_with_missing].isna().any(axis=1)]\n",
    "print(\"num na rows:\", len(bad_rows))\n",
    "print(\"na row indices:\", bad_rows.tolist()[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill any non-attacking unit with high ttk\n",
    "X[\"ttk_ds1_to_atk_str\"] = X[\"ttk_ds1_to_atk_str\"].fillna(1e6)\n",
    "\n",
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 571)\n",
      "(514,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [0,1,2,3,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Baselines</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        cv_acc  test_acc  test_roc_auc  test_precision  test_recall  test_f1\n",
      "mean  0.521645  0.519231           0.5             0.0          0.0      0.0\n",
      "std   0.000000  0.000000           0.0             0.0          0.0      0.0\n"
     ]
    }
   ],
   "source": [
    "def eval_from_proba(y_true, y_proba, thr=0.5):\n",
    "    y_hat = (y_proba >= thr).astype(int)\n",
    "    \n",
    "    return {\n",
    "        \"acc\": accuracy_score(y_true, y_hat),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_proba),\n",
    "        \"precision\": precision_score(y_true, y_hat, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_hat, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_hat, zero_division=0),\n",
    "    }\n",
    "\n",
    "def baseline_over_seeds(X, y, random_states, test_size=0.1):\n",
    "    rows = []\n",
    "\n",
    "    for r in random_states:\n",
    "        _, _, y_other, y_test = train_test_split(X, y, test_size=test_size, random_state=r, stratify=y)\n",
    "        p = float(np.mean(y_other))\n",
    "        y_proba = np.full(shape=len(y_test), fill_value=p, dtype=float)\n",
    "        m = eval_from_proba(y_test, y_proba)\n",
    "\n",
    "        rows.append({\"seed\": r, \"cv_acc\": 1-p, **{f\"test_{k}\": v for k, v in m.items()}}) # here majority is class 0\n",
    "    \n",
    "    out = pd.DataFrame(rows)\n",
    "    summary = out.drop(columns=[\"seed\"]).agg([\"mean\", \"std\"])\n",
    "    return out, summary\n",
    "\n",
    "baseline_df, baseline_summary = baseline_over_seeds(X, y, random_states)\n",
    "print(baseline_summary)\n",
    "baseline_summary.to_csv('../results/baseline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each random state:\n",
    "    initiate the parameter grid for these five models\n",
    "    - logistic regression, elastic net\n",
    "    - random forest, svc, xgboost, knn\n",
    "    train 5 models over this random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the preprocessors for data\n",
    "def make_preprocessor(num_ftrs, cat_ftrs) -> ColumnTransformer:\n",
    "    # define pipelines\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scalar', StandardScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        # fill nans with missing, treating as separate cat\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'))])\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_ftrs),\n",
    "            ('cat', categorical_transformer, cat_ftrs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "na_counts = X[num_ftrs].isna().sum().sort_values(ascending=False)\n",
    "print(na_counts[na_counts > 0].head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 865)\n",
      "(52, 865)\n",
      "(462, 865)\n",
      "(52, 865)\n",
      "(462, 864)\n",
      "(52, 864)\n",
      "(462, 866)\n",
      "(52, 866)\n",
      "(462, 865)\n",
      "(52, 865)\n"
     ]
    }
   ],
   "source": [
    "for r in random_states:\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.1, random_state=r, stratify=y)\n",
    "\n",
    "    prep = make_preprocessor(num_ftrs, cat_ftrs)\n",
    "    prep.fit(X_other)\n",
    "\n",
    "    Xt_other = prep.transform(X_other)\n",
    "    Xt_test  = prep.transform(X_test)\n",
    "\n",
    "    print(Xt_other.shape)\n",
    "    print(Xt_test.shape)\n",
    "\n",
    "    assert np.isnan(Xt_other).any() == False\n",
    "    assert np.isnan(Xt_test).any() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Make pipelines and grids</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make models n grids\n",
    "def make_models_and_grids(random_state: int) -> tuple:\n",
    "    models = {\n",
    "        'logreg_l2': LogisticRegression(max_iter=10000, random_state=random_state, penalty='l2', solver='lbfgs'),\n",
    "        'logreg_elastic': LogisticRegression(max_iter=10000, random_state=random_state, penalty='elasticnet', solver='saga', n_jobs=3),\n",
    "        'rfc': RandomForestClassifier(n_jobs=3, random_state=random_state, n_estimators=500),\n",
    "        'svc': SVC(kernel='rbf', probability=True, random_state=random_state),\n",
    "        'knn': KNeighborsClassifier(n_jobs=3),\n",
    "        'xgb': XGBTrainEarlyStoppingClassifier(random_state=random_state, n_estimators=10000, early_stopping_rounds=50,\n",
    "                validation_fraction=0.1, n_jobs=1)}\n",
    "\n",
    "    grids = {\n",
    "        \"logreg_l2\": {\n",
    "            \"clf__C\": [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "            \"clf__class_weight\": [None, \"balanced\"],\n",
    "        },\n",
    "\n",
    "        \"logreg_elastic\": {\n",
    "            \"clf__C\": [0.01, 0.1, 1, 10, 100],\n",
    "            \"clf__l1_ratio\": [0.5, 0.8, 0.9, 0.95, 1.00],\n",
    "            \"clf__class_weight\": [None, \"balanced\"],\n",
    "        },\n",
    "\n",
    "        \"rfc\": {\n",
    "            \"clf__n_estimators\": [400, 500, 600, 700, 800],\n",
    "            \"clf__max_depth\": [None, 2, 3, 5, 8],\n",
    "            \"clf__min_samples_leaf\": [3, 5, 8],\n",
    "            \"clf__max_features\": [\"sqrt\", 0.25, 0.5],\n",
    "            \"clf__class_weight\": [None, \"balanced\"],\n",
    "        },\n",
    "\n",
    "        \"svc\": {\n",
    "            \"clf__C\": [0.1, 0.5, 1, 2, 5, 10],\n",
    "            \"clf__gamma\": [\"scale\", 0.01, 0.1, 0.5, 1],\n",
    "            \"clf__class_weight\": [None, \"balanced\"],\n",
    "        },\n",
    "\n",
    "        \"knn\": {\n",
    "            \"clf__n_neighbors\": [1, 2, 3, 5, 9],\n",
    "            \"clf__weights\": [\"uniform\", \"distance\"],\n",
    "            \"clf__p\": [1, 2],\n",
    "        },\n",
    "\n",
    "        \"xgb\": {\n",
    "            \"clf__max_depth\": [0, 1, 2, 3],\n",
    "            \"clf__learning_rate\": [0.03, 0.1, 0.3, 0.6, 1],\n",
    "            \"clf__subsample\": [0.1, 0.2, 0.3, 0.6, 1.0],\n",
    "            \"clf__colsample_bytree\": [0.8, 0.9, 0.95, 0.98, 1.0],\n",
    "            \"clf__reg_lambda\": [0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return models, grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return 1d array of pos class\n",
    "def get_cont_scores(fitted_pipeline, X):\n",
    "    if hasattr(fitted_pipeline, \"decision_function\"):\n",
    "        scores = fitted_pipeline.decision_function(X)\n",
    "        return np.asarray(scores).ravel()\n",
    "\n",
    "    if hasattr(fitted_pipeline, \"predict_proba\"):\n",
    "        proba = fitted_pipeline.predict_proba(X)\n",
    "        return np.asarray(proba)[:, 1].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a model over all randoms\n",
    "def one_model(X, y, model_n: str, num_ftrs, cat_ftrs, random_states, test_size=0.1, scoring='accuracy'):\n",
    "    rows = []\n",
    "\n",
    "    out_dir = Path(\"../results/final/grid_pipe\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for r in random_states:\n",
    "        models, grids = make_models_and_grids(r)\n",
    "        base_model = models[model_n]\n",
    "        param_grid = grids[model_n]\n",
    "        \n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=test_size, random_state=r, stratify=y)\n",
    "\n",
    "        preprocessor = make_preprocessor(num_ftrs, cat_ftrs)\n",
    "\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('prep', preprocessor),\n",
    "            ('clf', clone(base_model))])\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=r)\n",
    "\n",
    "        gs = GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=-1, refit=True)\n",
    "        gs.fit(X_other, y_other)\n",
    "\n",
    "        # evaluate on held out test\n",
    "        best_pipe = gs.best_estimator_\n",
    "        y_pred = best_pipe.predict(X_test)\n",
    "        scores = get_cont_scores(best_pipe, X_test)\n",
    "        \n",
    "        # label metrics\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        roc_auc_s = roc_auc_score(y_test, scores)\n",
    "\n",
    "        rows.append({\n",
    "            \"seed\": r,\n",
    "            'model': model_n,\n",
    "            'best_cv_acc': gs.best_score_,\n",
    "            'test_acc': accuracy_score(y_test, y_pred),\n",
    "            'test_roc_auc': roc_auc_s,\n",
    "            'best_params': gs.best_params_,\n",
    "            \"test_precision\": prec,\n",
    "            \"test_recall\": rec,\n",
    "            \"test_f1\": f1})\n",
    "        \n",
    "        # save grid info\n",
    "        pd.DataFrame(gs.cv_results_).to_csv(out_dir / f\"{model_n}_seed{r}_cv_results.csv\", index=False)\n",
    "        with open(out_dir/f\"{model_n}_seed{r}_best_pipe.pkl\", \"wb\") as f:\n",
    "            pickle.dump(best_pipe, f)\n",
    "        with open(out_dir/f\"{model_n}_seed{r}_X_test.pkl\", \"wb\") as f:\n",
    "            pickle.dump(X_test, f)\n",
    "        with open(out_dir/f\"{model_n}_seed{r}_y_test.pkl\", \"wb\") as f:\n",
    "            pickle.dump(y_test, f)\n",
    "        \n",
    "        print(f'done with random state {r}')\n",
    "\n",
    "    print(f'done with model {model_n}')\n",
    "    \n",
    "    # saving results\n",
    "    out = pd.DataFrame(rows)\n",
    "    metric_cols = [\"best_cv_acc\", \"test_acc\", \"test_precision\", \"test_recall\", \"test_f1\",\"test_roc_auc\"]\n",
    "    summary = out[metric_cols].agg(['mean','std']).T\n",
    "    summary = summary.reset_index().rename(columns={'index': 'metric'})\n",
    "\n",
    "    return out, summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['logreg_l2', 'logreg_elastic', 'rfc', 'svc', 'knn', 'xgb']\n",
    "\n",
    "# 'logreg_l2', 'logreg_elastic', 'rfc', 'svc', 'knn', 'xgb'\n",
    "\n",
    "# for m in models:\n",
    "#     out, summary = one_model(\n",
    "#         X=X,\n",
    "#         y=y,\n",
    "#         model_n=m,\n",
    "#         num_ftrs=num_ftrs,\n",
    "#         cat_ftrs=cat_ftrs,\n",
    "#         random_states=random_states,\n",
    "#         test_size=0.1,\n",
    "#         scoring=\"accuracy\")\n",
    "\n",
    "#     out.to_csv(f'../results/final/{m}.csv', index=False)\n",
    "#     summary.to_csv(f'../results/final/{m}_agg.csv', index=False)\n",
    "#     print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
